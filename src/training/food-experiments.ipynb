{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6079287,"sourceType":"datasetVersion","datasetId":3480259}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ• Universal Food Classification Training\n## Experiments: Inception v3 & Inception-ResNet-v2 (Head & Full Backbone)\n\n**Select experiment by changing `EXPERIMENT_ID`:**\n- 1: Inception v3 (Head only)\n- 2: Inception-ResNet-v2 (Head only) \n- 3: Inception v3 (Full backbone)\n- 4: Inception-ResNet-v2 (Full backbone)","metadata":{}},{"cell_type":"code","source":"# ðŸŸ¦ Cell 1 â€“ Setup and Dependencies\n!git clone https://github.com/Romaha095/architectural-comparison-inception.git\n%cd architectural-comparison-inception\n!git checkout inception-resnet-v2_experiments\n!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T19:20:52.359128Z","iopub.execute_input":"2026-01-29T19:20:52.359790Z","iopub.status.idle":"2026-01-29T19:21:00.481301Z","shell.execute_reply.started":"2026-01-29T19:20:52.359751Z","shell.execute_reply":"2026-01-29T19:21:00.480393Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'architectural-comparison-inception'...\nremote: Enumerating objects: 171, done.\u001b[K\nremote: Counting objects: 100% (44/44), done.\u001b[K\nremote: Compressing objects: 100% (34/34), done.\u001b[K\nremote: Total 171 (delta 24), reused 9 (delta 9), pack-reused 127 (from 1)\u001b[K\nReceiving objects: 100% (171/171), 63.72 KiB | 7.08 MiB/s, done.\nResolving deltas: 100% (69/69), done.\n/kaggle/working/architectural-comparison-inception/architectural-comparison-inception/architectural-comparison-inception/architectural-comparison-inception/architectural-comparison-inception/architectural-comparison-inception/architectural-comparison-inception/architectural-comparison-inception\nBranch 'inception-resnet-v2_experiments' set up to track remote branch 'inception-resnet-v2_experiments' from 'origin'.\nSwitched to a new branch 'inception-resnet-v2_experiments'\nLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.0.2)\nRequirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.15.3)\nRequirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\nRequirement already satisfied: scikit-learn>=1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (1.6.1)\nRequirement already satisfied: tqdm>=4.66 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.67.1)\nRequirement already satisfied: timm>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.0.20)\nRequirement already satisfied: torchvision>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.23.0+cu126)\nRequirement already satisfied: jupyter in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.1.1)\nRequirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (6.17.1)\nRequirement already satisfied: black in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (25.12.0)\nRequirement already satisfied: isort in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (7.0.0)\nRequirement already satisfied: flake8 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (7.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->-r requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->-r requirements.txt (line 3)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->-r requirements.txt (line 3)) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->-r requirements.txt (line 3)) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->-r requirements.txt (line 3)) (26.0rc2)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->-r requirements.txt (line 3)) (11.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->-r requirements.txt (line 3)) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->-r requirements.txt (line 3)) (2.9.0.post0)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4->-r requirements.txt (line 4)) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4->-r requirements.txt (line 4)) (3.6.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm>=1.0.0->-r requirements.txt (line 7)) (2.8.0+cu126)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm>=1.0.0->-r requirements.txt (line 7)) (6.0.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm>=1.0.0->-r requirements.txt (line 7)) (0.36.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm>=1.0.0->-r requirements.txt (line 7)) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm>=1.0.0->-r requirements.txt (line 7)) (3.4.0)\nRequirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter->-r requirements.txt (line 10)) (6.5.7)\nRequirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter->-r requirements.txt (line 10)) (6.6.3)\nRequirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter->-r requirements.txt (line 10)) (6.4.5)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from jupyter->-r requirements.txt (line 10)) (8.1.5)\nRequirement already satisfied: jupyterlab in /usr/local/lib/python3.12/dist-packages (from jupyter->-r requirements.txt (line 10)) (3.6.8)\nRequirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 11)) (1.8.15)\nRequirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 11)) (7.34.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 11)) (7.4.9)\nRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 11)) (0.1.7)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 11)) (1.6.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 11)) (5.9.5)\nRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 11)) (26.2.1)\nRequirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 11)) (6.5.1)\nRequirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 11)) (5.7.1)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black->-r requirements.txt (line 13)) (8.3.1)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from black->-r requirements.txt (line 13)) (1.1.0)\nRequirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from black->-r requirements.txt (line 13)) (1.0.3)\nRequirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black->-r requirements.txt (line 13)) (4.5.1)\nRequirement already satisfied: pytokens>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from black->-r requirements.txt (line 13)) (0.3.0)\nRequirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from flake8->-r requirements.txt (line 15)) (0.7.0)\nRequirement already satisfied: pycodestyle<2.15.0,>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from flake8->-r requirements.txt (line 15)) (2.14.0)\nRequirement already satisfied: pyflakes<3.5.0,>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from flake8->-r requirements.txt (line 15)) (3.4.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 11)) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 11)) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 11)) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 11)) (3.0.52)\nRequirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 11)) (2.19.2)\nRequirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 11)) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 11)) (4.9.0)\nRequirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 11)) (0.4)\nRequirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 11)) (5.9.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8->-r requirements.txt (line 3)) (1.17.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm>=1.0.0->-r requirements.txt (line 7)) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm>=1.0.0->-r requirements.txt (line 7)) (1.2.1rc0)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 10)) (0.2.3)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 10)) (4.0.15)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 10)) (3.0.15)\nRequirement already satisfied: jupyterlab-server~=2.19 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 10)) (2.28.0)\nRequirement already satisfied: jupyter-server<3,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 10)) (2.12.5)\nRequirement already satisfied: jupyter-ydoc~=0.2.4 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 10)) (0.2.5)\nRequirement already satisfied: jupyter-server-ydoc~=0.8.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 10)) (0.8.0)\nRequirement already satisfied: nbclassic in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 10)) (1.3.3)\nRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (25.1.0)\nRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (0.2.0)\nRequirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (5.10.4)\nRequirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (0.18.1)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r requirements.txt (line 10)) (0.23.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.3.0)\nRequirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (6.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (1.5.1)\nRequirement already satisfied: testpath in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.6.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (4.13.5)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 10)) (3.0.3)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 11)) (0.8.5)\nRequirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (4.12.1)\nRequirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.12.0)\nRequirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.5.3)\nRequirement already satisfied: overrides in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (7.7.0)\nRequirement already satisfied: websocket-client in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (1.9.0)\nRequirement already satisfied: jupyter-server-fileid<1,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.9.3)\nRequirement already satisfied: ypy-websocket<0.9.0,>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.8.4)\nRequirement already satisfied: y-py<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-ydoc~=0.2.4->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.6.2)\nRequirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server~=2.19->jupyterlab->jupyter->-r requirements.txt (line 10)) (2.17.0)\nRequirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server~=2.19->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.13.0)\nRequirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server~=2.19->jupyterlab->jupyter->-r requirements.txt (line 10)) (4.25.1)\nRequirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.2.4)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook->jupyter->-r requirements.txt (line 10)) (2.21.2)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 11)) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 11)) (0.2.14)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm>=1.0.0->-r requirements.txt (line 7)) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm>=1.0.0->-r requirements.txt (line 7)) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm>=1.0.0->-r requirements.txt (line 7)) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm>=1.0.0->-r requirements.txt (line 7)) (2026.1.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm>=1.0.0->-r requirements.txt (line 7)) (1.3.0)\nRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 10)) (25.1.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 10)) (2.8)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 10)) (0.5.1)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab->jupyter->-r requirements.txt (line 10)) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab->jupyter->-r requirements.txt (line 10)) (2025.9.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.37.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.27.1)\nRequirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (4.0.0)\nRequirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.1.1)\nRequirement already satisfied: aiofiles<23,>=22.1.0 in /usr/local/lib/python3.12/dist-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (22.1.0)\nRequirement already satisfied: aiosqlite<1,>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (0.22.1)\nRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 10)) (2.0.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 10)) (2.23)\nRequirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (1.5.1)\nRequirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (3.0.0)\nRequirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (1.1.0)\nRequirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (1.3.0)\nRequirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (24.11.1)\nRequirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (1.3.0)\nRequirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (1.4.0)\nRequirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter->-r requirements.txt (line 10)) (2025.2)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# ðŸŸ© Cell 2 â€“ Universal Training Script with All Features\n\nimport os\nimport sys\nimport time\nimport logging\nimport shutil\nfrom pathlib import Path\nfrom datetime import datetime\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.amp import autocast, GradScaler\nfrom torchvision import transforms, datasets\n\nimport timm\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\nfrom tqdm import tqdm\n\n# ============================================================================\n# ðŸŽ¯ EXPERIMENT CONFIGURATION - CHANGE THIS TO SELECT EXPERIMENT\n# ============================================================================\nEXPERIMENT_ID = 4  # Options: 1, 2, 3, 4\n\n# Experiment configurations\nEXPERIMENTS = {\n    1: {'model': 'inception_v3', 'train_mode': 'head', 'name': 'InceptionV3-Head'},\n    2: {'model': 'inception_resnet_v2', 'train_mode': 'head', 'name': 'InceptionResNetV2-Head'},\n    3: {'model': 'inception_v3', 'train_mode': 'full', 'name': 'InceptionV3-FullBackbone'},\n    4: {'model': 'inception_resnet_v2', 'train_mode': 'full', 'name': 'InceptionResNetV2-FullBackbone'}\n}\n\n# Validate experiment ID\nif EXPERIMENT_ID not in EXPERIMENTS:\n    raise ValueError(f\"Invalid EXPERIMENT_ID: {EXPERIMENT_ID}. Must be 1, 2, 3, or 4.\")\n\nEXP_CONFIG = EXPERIMENTS[EXPERIMENT_ID]\nMODEL_TYPE = EXP_CONFIG['model']\nTRAIN_MODE = EXP_CONFIG['train_mode']  # 'head' or 'full'\nEXP_NAME = EXP_CONFIG['name']\n\nprint(f\"\\n{'='*80}\")\nprint(f\"ðŸš€ EXPERIMENT {EXPERIMENT_ID}: {EXP_NAME}\")\nprint(f\"   Model: {MODEL_TYPE}\")\nprint(f\"   Training mode: {TRAIN_MODE} ({'Head only' if TRAIN_MODE == 'head' else 'Full backbone'})\")\nprint(f\"{'='*80}\\n\")\n\n# ============================================================================\n# ðŸ“‹ HYPERPARAMETERS\n# ============================================================================\nNUM_EPOCHS = 10\nBATCH_SIZE = 32\nLEARNING_RATE = 0.001\nIMG_SIZE = 299  # Standard for Inception architectures\nNUM_WORKERS = 4\nUSE_AMP = True  # Mixed precision training\n\n# Auto-detect dataset path\nif os.path.exists('/kaggle/input/food-image-classification-dataset/Food Classification dataset'):\n    DATA_ROOT = Path('/kaggle/input/food-image-classification-dataset/Food Classification dataset')\n    print(f\"âœ… Found dataset at: {DATA_ROOT}\")\nelif os.path.exists('/kaggle/input/food-101/images'):\n    DATA_ROOT = Path('/kaggle/input/food-101/images')\n    print(f\"âœ… Found dataset at: {DATA_ROOT}\")\nelse:\n    raise FileNotFoundError(\"Dataset not found! Please check the Kaggle dataset path.\")\n\nOUTPUT_DIR = Path(f'/kaggle/working/exp{EXPERIMENT_ID}_{EXP_NAME}')\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\n# ============================================================================\n# ðŸ“Š LOGGING SETUP\n# ============================================================================\nlog_file = OUTPUT_DIR / 'training.log'\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s | %(levelname)s | %(name)s | %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S',\n    handlers=[\n        logging.FileHandler(log_file),\n        logging.StreamHandler(sys.stdout)\n    ]\n)\nlogger = logging.getLogger('main')\n\nlogger.info(f\"Starting Experiment {EXPERIMENT_ID}: {EXP_NAME}\")\nlogger.info(f\"Model: {MODEL_TYPE}, Training mode: {TRAIN_MODE}\")\nlogger.info(f\"Output directory: {OUTPUT_DIR}\")\n\n# ============================================================================\n# ðŸ”§ DEVICE SETUP\n# ============================================================================\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nlogger.info(f\"Using device: {device}\")\nif torch.cuda.is_available():\n    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n\n# ============================================================================\n# ðŸ–¼ï¸ DATA PREPARATION\n# ============================================================================\nlogger.info(\"Preparing datasets...\")\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_test_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Check if data is already split into train/val/test subdirectories\nhas_splits = (DATA_ROOT / 'train').exists() and (DATA_ROOT / 'validation').exists()\n\nif has_splits:\n    logger.info(\"Loading pre-split datasets...\")\n    train_dataset = datasets.ImageFolder(DATA_ROOT / 'train', transform=train_transform)\n    val_dataset = datasets.ImageFolder(DATA_ROOT / 'validation', transform=val_test_transform)\n    test_dataset = datasets.ImageFolder(DATA_ROOT / 'test', transform=val_test_transform)\nelse:\n    # Load all data and split manually\n    logger.info(\"No pre-split found. Creating train/val/test splits (70/15/15)...\")\n    full_dataset = datasets.ImageFolder(DATA_ROOT)\n    \n    # Calculate split sizes\n    total_size = len(full_dataset)\n    train_size = int(0.70 * total_size)\n    val_size = int(0.15 * total_size)\n    test_size = total_size - train_size - val_size\n    \n    # Split dataset\n    train_dataset, val_dataset, test_dataset = random_split(\n        full_dataset, [train_size, val_size, test_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n    \n    # Apply transforms\n    train_dataset.dataset.transform = train_transform\n    val_dataset.dataset.transform = val_test_transform\n    test_dataset.dataset.transform = val_test_transform\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n                         num_workers=NUM_WORKERS, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n                       num_workers=NUM_WORKERS, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n                        num_workers=NUM_WORKERS, pin_memory=True)\n\n# Get number of classes\nif has_splits:\n    NUM_CLASSES = len(train_dataset.classes)\n    class_names = train_dataset.classes\nelse:\n    NUM_CLASSES = len(train_dataset.dataset.classes)\n    class_names = train_dataset.dataset.classes\n\nlogger.info(f\"Train samples: {len(train_dataset)}\")\nlogger.info(f\"Val samples: {len(val_dataset)}\")\nlogger.info(f\"Test samples: {len(test_dataset)}\")\nlogger.info(f\"Number of classes: {NUM_CLASSES}\")\nlogger.info(f\"Classes: {class_names[:5]}... (showing first 5)\")\n\n# ============================================================================\n# ðŸ—ï¸ MODEL CREATION\n# ============================================================================\ndef create_model(model_type, num_classes, train_mode):\n    \"\"\"Create and configure model based on type and training mode.\n    \n    Args:\n        model_type: 'inception_v3' or 'inception_resnet_v2'\n        num_classes: Number of output classes\n        train_mode: 'head' (freeze backbone) or 'full' (train everything)\n    \"\"\"\n    logger.info(f\"Creating model: {model_type}\")\n    \n    # Create model with pretrained weights\n    model = timm.create_model(model_type, pretrained=True, num_classes=num_classes)\n    \n    if train_mode == 'head':\n        # Freeze all layers except the classifier head\n        logger.info(\"Freezing backbone layers (training head only)\")\n        for param in model.parameters():\n            param.requires_grad = False\n        \n        # Unfreeze classifier head\n        if model_type == 'inception_v3':\n            for param in model.fc.parameters():\n                param.requires_grad = True\n        elif model_type == 'inception_resnet_v2':\n            for param in model.classif.parameters():\n                param.requires_grad = True\n    else:\n        # Train full backbone\n        logger.info(\"Training full backbone (all layers trainable)\")\n        for param in model.parameters():\n            param.requires_grad = True\n    \n    # Count parameters\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    logger.info(f\"Model: {model_type}\")\n    logger.info(f\"  Total params     = {total_params:,}\")\n    logger.info(f\"  Trainable params = {trainable_params:,}\")\n    logger.info(f\"  Frozen params    = {total_params - trainable_params:,}\")\n    \n    return model\n\nmodel = create_model(MODEL_TYPE, NUM_CLASSES, TRAIN_MODE).to(device)\n\n# ============================================================================\n# ðŸŽ“ TRAINING SETUP\n# ============================================================================\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\nscaler = GradScaler(device='cuda', enabled=USE_AMP)\n\nlogger.info(f\"Optimizer: Adam (lr={LEARNING_RATE})\")\nlogger.info(f\"Mixed precision: {USE_AMP}\")\n\n# ============================================================================\n# ðŸ“ˆ TRAINING & EVALUATION FUNCTIONS\n# ============================================================================\ndef train_epoch(model, loader, criterion, optimizer, scaler, device, use_amp):\n    \"\"\"Train for one epoch.\"\"\"\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(loader, desc='Training', leave=False)\n    for inputs, labels in pbar:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        with autocast(device_type='cuda', enabled=use_amp):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        running_loss += loss.item() * inputs.size(0)\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})\n    \n    epoch_loss = running_loss / total\n    epoch_acc = 100. * correct / total\n    return epoch_loss, epoch_acc\n\ndef evaluate(model, loader, criterion, device):\n    \"\"\"Evaluate model on validation/test set.\"\"\"\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(loader, desc='Evaluating', leave=False):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    epoch_loss = running_loss / total\n    epoch_acc = 100. * correct / total\n    return epoch_loss, epoch_acc\n\ndef compute_detailed_metrics(model, loader, device, num_classes):\n    \"\"\"Compute detailed metrics including precision, recall, F1, and throughput.\"\"\"\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_times = []\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(loader, desc='Computing metrics', leave=False):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Measure inference time\n            start_time = time.time()\n            outputs = model(inputs)\n            torch.cuda.synchronize()  # Wait for GPU to finish\n            end_time = time.time()\n            \n            batch_time = end_time - start_time\n            all_times.append(batch_time)\n            \n            _, predicted = outputs.max(1)\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Convert to numpy arrays\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    \n    # Calculate metrics\n    accuracy = 100. * (all_preds == all_labels).sum() / len(all_labels)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        all_labels, all_preds, average='macro', zero_division=0\n    )\n    \n    # Calculate latency and throughput\n    total_time = sum(all_times)\n    total_images = len(all_labels)\n    latency_ms = (total_time / total_images) * 1000  # ms per image\n    throughput = total_images / total_time  # images per second\n    \n    metrics = {\n        'accuracy': accuracy,\n        'precision': precision * 100,\n        'recall': recall * 100,\n        'f1': f1 * 100,\n        'latency_ms': latency_ms,\n        'throughput': throughput,\n        'predictions': all_preds,\n        'labels': all_labels\n    }\n    \n    return metrics\n\ndef plot_confusion_matrix(y_true, y_pred, class_names, save_path):\n    \"\"\"Plot and save confusion matrix.\"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # For large number of classes, show simplified version\n    plt.figure(figsize=(20, 18))\n    \n    # Normalize confusion matrix\n    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    \n    sns.heatmap(cm_normalized, annot=False, fmt='.2f', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names,\n                cbar_kws={'label': 'Normalized Count'})\n    \n    plt.title(f'Confusion Matrix - {EXP_NAME}', fontsize=16, pad=20)\n    plt.ylabel('True Label', fontsize=12)\n    plt.xlabel('Predicted Label', fontsize=12)\n    plt.xticks(rotation=90, fontsize=6)\n    plt.yticks(rotation=0, fontsize=6)\n    plt.tight_layout()\n    \n    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    logger.info(f\"Confusion matrix saved to {save_path}\")\n    plt.close()\n\n# ============================================================================\n# ðŸš‚ TRAINING LOOP\n# ============================================================================\nbest_val_acc = 0.0\ntrain_history = {'loss': [], 'acc': []}\nval_history = {'loss': [], 'acc': []}\n\nfor epoch in range(1, NUM_EPOCHS + 1):\n    logger.info(f\"Epoch {epoch}/{NUM_EPOCHS}\")\n    \n    # Train\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, \n                                       scaler, device, USE_AMP)\n    train_history['loss'].append(train_loss)\n    train_history['acc'].append(train_acc)\n    \n    # Validate\n    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n    val_history['loss'].append(val_loss)\n    val_history['acc'].append(val_acc)\n    \n    logger.info(f\"  Train: loss={train_loss:.4f}, acc={train_acc:.2f}% | \"\n               f\"Val: loss={val_loss:.4f}, acc={val_acc:.2f}%\")\n    \n    # Save best model\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        checkpoint_path = OUTPUT_DIR / 'best_model.pt'\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_acc': val_acc,\n            'val_loss': val_loss,\n            'experiment_config': EXP_CONFIG,\n            'hyperparameters': {\n                'num_epochs': NUM_EPOCHS,\n                'batch_size': BATCH_SIZE,\n                'learning_rate': LEARNING_RATE,\n                'img_size': IMG_SIZE\n            }\n        }, checkpoint_path)\n        logger.info(f\"  New best val acc: {val_acc:.2f}% (checkpoint: {checkpoint_path.name})\")\n    \n    # Learning rate scheduling\n    scheduler.step(val_acc)\n\n# Save final model\nfinal_model_path = OUTPUT_DIR / 'final_model.pt'\ntorch.save({\n    'epoch': NUM_EPOCHS,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'train_history': train_history,\n    'val_history': val_history,\n    'experiment_config': EXP_CONFIG,\n}, final_model_path)\nlogger.info(f\"Final model saved to {final_model_path}\")\n\n# ============================================================================\n# ðŸ§ª FINAL TEST EVALUATION\n# ============================================================================\nlogger.info(\"Training finished. Running final test evaluation...\")\n\n# Load best model\ncheckpoint = torch.load(OUTPUT_DIR / 'best_model.pt')\nmodel.load_state_dict(checkpoint['model_state_dict'])\n\n# Test evaluation with cross-entropy loss\ntest_loss, test_acc = evaluate(model, test_loader, criterion, device)\nlogger.info(f\"Test (CE): loss={test_loss:.4f}, acc={test_acc:.2f}%\")\n\n# Compute detailed metrics\ntest_metrics = compute_detailed_metrics(model, test_loader, device, NUM_CLASSES)\n\nlogger.info(f\"Test metrics: accuracy={test_metrics['accuracy']:.2f}%, \"\n           f\"precision={test_metrics['precision']:.2f}%, \"\n           f\"recall={test_metrics['recall']:.2f}%, \"\n           f\"f1={test_metrics['f1']:.2f}%, \"\n           f\"latency={test_metrics['latency_ms']:.2f} ms/img, \"\n           f\"throughput={test_metrics['throughput']:.2f} img/s\")\n\n# ============================================================================\n# ðŸ“Š CONFUSION MATRIX\n# ============================================================================\nlogger.info(\"Generating confusion matrix...\")\ncm_path = OUTPUT_DIR / 'confusion_matrix.png'\nplot_confusion_matrix(test_metrics['labels'], test_metrics['predictions'], \n                     class_names, cm_path)\n\n# ============================================================================\n# ðŸ“ˆ PLOT TRAINING HISTORY\n# ============================================================================\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n\n# Loss plot\nax1.plot(range(1, NUM_EPOCHS + 1), train_history['loss'], 'b-', label='Train Loss', linewidth=2)\nax1.plot(range(1, NUM_EPOCHS + 1), val_history['loss'], 'r-', label='Val Loss', linewidth=2)\nax1.set_xlabel('Epoch', fontsize=12)\nax1.set_ylabel('Loss', fontsize=12)\nax1.set_title(f'Training & Validation Loss - {EXP_NAME}', fontsize=14)\nax1.legend(fontsize=10)\nax1.grid(True, alpha=0.3)\n\n# Accuracy plot\nax2.plot(range(1, NUM_EPOCHS + 1), train_history['acc'], 'b-', label='Train Acc', linewidth=2)\nax2.plot(range(1, NUM_EPOCHS + 1), val_history['acc'], 'r-', label='Val Acc', linewidth=2)\nax2.set_xlabel('Epoch', fontsize=12)\nax2.set_ylabel('Accuracy (%)', fontsize=12)\nax2.set_title(f'Training & Validation Accuracy - {EXP_NAME}', fontsize=14)\nax2.legend(fontsize=10)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nhistory_path = OUTPUT_DIR / 'training_history.png'\nplt.savefig(history_path, dpi=150, bbox_inches='tight')\nlogger.info(f\"Training history plot saved to {history_path}\")\nplt.close()\n\n# ============================================================================\n# ðŸ’¾ SAVE FINAL RESULTS\n# ============================================================================\nresults = {\n    'experiment_id': EXPERIMENT_ID,\n    'experiment_name': EXP_NAME,\n    'model_type': MODEL_TYPE,\n    'train_mode': TRAIN_MODE,\n    'best_val_acc': best_val_acc,\n    'test_metrics': {\n        'loss': test_loss,\n        'accuracy': test_metrics['accuracy'],\n        'precision': test_metrics['precision'],\n        'recall': test_metrics['recall'],\n        'f1': test_metrics['f1'],\n        'latency_ms': test_metrics['latency_ms'],\n        'throughput': test_metrics['throughput']\n    },\n    'hyperparameters': {\n        'num_epochs': NUM_EPOCHS,\n        'batch_size': BATCH_SIZE,\n        'learning_rate': LEARNING_RATE,\n        'img_size': IMG_SIZE\n    },\n    'dataset_info': {\n        'num_classes': NUM_CLASSES,\n        'train_samples': len(train_dataset),\n        'val_samples': len(val_dataset),\n        'test_samples': len(test_dataset)\n    }\n}\n\nimport json\nresults_path = OUTPUT_DIR / 'results.json'\nwith open(results_path, 'w') as f:\n    json.dump(results, f, indent=2)\n\nlogger.info(f\"Results saved to {results_path}\")\nlogger.info(\"\\n\" + \"=\"*80)\nlogger.info(f\"âœ… Experiment {EXPERIMENT_ID} completed successfully!\")\nlogger.info(f\"ðŸ“ All outputs saved to: {OUTPUT_DIR}\")\nlogger.info(\"=\"*80)\n\nprint(f\"\\n\\n{'='*80}\")\nprint(f\"ðŸŽ‰ EXPERIMENT {EXPERIMENT_ID} COMPLETED!\")\nprint(f\"{'='*80}\")\nprint(f\"\\nðŸ“Š FINAL RESULTS:\")\nprint(f\"  Model: {MODEL_TYPE}\")\nprint(f\"  Training mode: {TRAIN_MODE}\")\nprint(f\"  Best validation accuracy: {best_val_acc:.2f}%\")\nprint(f\"  Test accuracy: {test_metrics['accuracy']:.2f}%\")\nprint(f\"  Test precision: {test_metrics['precision']:.2f}%\")\nprint(f\"  Test recall: {test_metrics['recall']:.2f}%\")\nprint(f\"  Test F1: {test_metrics['f1']:.2f}%\")\nprint(f\"  Inference latency: {test_metrics['latency_ms']:.2f} ms/img\")\nprint(f\"  Throughput: {test_metrics['throughput']:.2f} img/s\")\nprint(f\"\\nðŸ“ Outputs saved to: {OUTPUT_DIR}\")\nprint(f\"  - best_model.pt\")\nprint(f\"  - final_model.pt\")\nprint(f\"  - confusion_matrix.png\")\nprint(f\"  - training_history.png\")\nprint(f\"  - results.json\")\nprint(f\"  - training.log\")\nprint(f\"{'='*80}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T19:21:03.471844Z","iopub.execute_input":"2026-01-29T19:21:03.472166Z","iopub.status.idle":"2026-01-29T20:16:41.868355Z","shell.execute_reply.started":"2026-01-29T19:21:03.472136Z","shell.execute_reply":"2026-01-29T20:16:41.867746Z"}},"outputs":[{"name":"stderr","text":"2026-01-29 19:21:03 | INFO | main | Starting Experiment 4: InceptionResNetV2-FullBackbone\n","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nðŸš€ EXPERIMENT 4: InceptionResNetV2-FullBackbone\n   Model: inception_resnet_v2\n   Training mode: full (Full backbone)\n================================================================================\n\nâœ… Found dataset at: /kaggle/input/food-image-classification-dataset/Food Classification dataset\n2026-01-29 19:21:03 | INFO | main | Starting Experiment 4: InceptionResNetV2-FullBackbone\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:03 | INFO | main | Model: inception_resnet_v2, Training mode: full\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:03 | INFO | main | Model: inception_resnet_v2, Training mode: full\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:03 | INFO | main | Output directory: /kaggle/working/exp4_InceptionResNetV2-FullBackbone\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:03 | INFO | main | Output directory: /kaggle/working/exp4_InceptionResNetV2-FullBackbone\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:03 | INFO | main | Using device: cuda\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:03 | INFO | main | Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:03 | INFO | main | GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:03 | INFO | main | GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:03 | INFO | main | Preparing datasets...\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:03 | INFO | main | Preparing datasets...\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:03 | INFO | main | No pre-split found. Creating train/val/test splits (70/15/15)...\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:03 | INFO | main | No pre-split found. Creating train/val/test splits (70/15/15)...\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:26 | INFO | main | Train samples: 16711\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:26 | INFO | main | Train samples: 16711\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:26 | INFO | main | Val samples: 3580\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:26 | INFO | main | Val samples: 3580\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:26 | INFO | main | Test samples: 3582\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:26 | INFO | main | Test samples: 3582\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:26 | INFO | main | Number of classes: 34\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:26 | INFO | main | Number of classes: 34\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:26 | INFO | main | Classes: ['Baked Potato', 'Crispy Chicken', 'Donut', 'Fries', 'Hot Dog']... (showing first 5)\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:26 | INFO | main | Classes: ['Baked Potato', 'Crispy Chicken', 'Donut', 'Fries', 'Hot Dog']... (showing first 5)\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:26 | INFO | main | Creating model: inception_resnet_v2\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:26 | INFO | main | Creating model: inception_resnet_v2\n2026-01-29 19:21:26 | INFO | timm.models._builder | Loading pretrained weights from Hugging Face hub (timm/inception_resnet_v2.tf_in1k)\n2026-01-29 19:21:27 | INFO | timm.models._hub | [timm/inception_resnet_v2.tf_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n2026-01-29 19:21:27 | INFO | timm.models._builder | Missing keys (classif.weight, classif.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:27 | INFO | main | Training full backbone (all layers trainable)\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:27 | INFO | main | Training full backbone (all layers trainable)\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:27 | INFO | main | Model: inception_resnet_v2\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:27 | INFO | main | Model: inception_resnet_v2\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:27 | INFO | main |   Total params     = 54,358,722\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:27 | INFO | main |   Total params     = 54,358,722\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:27 | INFO | main |   Trainable params = 54,358,722\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:27 | INFO | main |   Trainable params = 54,358,722\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:27 | INFO | main |   Frozen params    = 0\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:27 | INFO | main |   Frozen params    = 0\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:27 | INFO | main | Optimizer: Adam (lr=0.001)\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:27 | INFO | main | Optimizer: Adam (lr=0.001)\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:27 | INFO | main | Mixed precision: True\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:27 | INFO | main | Mixed precision: True\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:21:27 | INFO | main | Epoch 1/10\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:21:27 | INFO | main | Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"Training:  15%|â–ˆâ–Œ        | 79/523 [00:46<04:17,  1.72it/s, loss=1.8475, acc=42.64%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nTraining:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 193/523 [01:52<03:11,  1.72it/s, loss=1.4598, acc=53.32%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 19:26:53 | INFO | main |   Train: loss=1.1728, acc=65.36% | Val: loss=1.1278, acc=65.98%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:26:53 | INFO | main |   Train: loss=1.1728, acc=65.36% | Val: loss=1.1278, acc=65.98%\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:26:54 | INFO | main |   New best val acc: 65.98% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:26:54 | INFO | main |   New best val acc: 65.98% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:26:54 | INFO | main | Epoch 2/10\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:26:54 | INFO | main | Epoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/523 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 19:32:20 | INFO | main |   Train: loss=0.6126, acc=80.77% | Val: loss=0.7216, acc=78.04%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:32:20 | INFO | main |   Train: loss=0.6126, acc=80.77% | Val: loss=0.7216, acc=78.04%\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:32:22 | INFO | main |   New best val acc: 78.04% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:32:22 | INFO | main |   New best val acc: 78.04% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:32:22 | INFO | main | Epoch 3/10\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:32:22 | INFO | main | Epoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"Training:  28%|â–ˆâ–ˆâ–Š       | 145/523 [01:25<03:39,  1.72it/s, loss=0.2390, acc=87.61%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nTraining:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 300/523 [02:55<02:09,  1.72it/s, loss=0.5134, acc=87.31%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 19:37:48 | INFO | main |   Train: loss=0.4303, acc=86.64% | Val: loss=0.6785, acc=79.39%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:37:48 | INFO | main |   Train: loss=0.4303, acc=86.64% | Val: loss=0.6785, acc=79.39%\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:37:49 | INFO | main |   New best val acc: 79.39% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:37:49 | INFO | main |   New best val acc: 79.39% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:37:49 | INFO | main | Epoch 4/10\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:37:49 | INFO | main | Epoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 213/523 [02:04<03:00,  1.72it/s, loss=0.2384, acc=91.15%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 19:43:15 | INFO | main |   Train: loss=0.3087, acc=90.19% | Val: loss=0.6091, acc=81.76%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:43:15 | INFO | main |   Train: loss=0.3087, acc=90.19% | Val: loss=0.6091, acc=81.76%\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:43:17 | INFO | main |   New best val acc: 81.76% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:43:17 | INFO | main |   New best val acc: 81.76% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:43:17 | INFO | main | Epoch 5/10\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:43:17 | INFO | main | Epoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|â–ˆâ–ˆâ–‰       | 152/523 [01:29<03:35,  1.72it/s, loss=0.0903, acc=94.59%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nTraining:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 205/523 [01:59<03:04,  1.72it/s, loss=0.1077, acc=94.28%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 19:48:43 | INFO | main |   Train: loss=0.2297, acc=92.61% | Val: loss=0.6646, acc=81.42%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:48:43 | INFO | main |   Train: loss=0.2297, acc=92.61% | Val: loss=0.6646, acc=81.42%\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:48:43 | INFO | main | Epoch 6/10\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:48:43 | INFO | main | Epoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"Training:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 176/523 [01:43<03:22,  1.72it/s, loss=0.1380, acc=93.47%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nTraining:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 283/523 [02:45<02:19,  1.72it/s, loss=0.4468, acc=93.85%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 19:54:09 | INFO | main |   Train: loss=0.1939, acc=93.66% | Val: loss=0.5701, acc=84.33%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:54:09 | INFO | main |   Train: loss=0.1939, acc=93.66% | Val: loss=0.5701, acc=84.33%\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:54:10 | INFO | main |   New best val acc: 84.33% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:54:10 | INFO | main |   New best val acc: 84.33% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:54:10 | INFO | main | Epoch 7/10\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:54:10 | INFO | main | Epoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"Training:  14%|â–ˆâ–        | 74/523 [00:44<04:21,  1.72it/s, loss=0.6869, acc=93.37%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 19:59:38 | INFO | main |   Train: loss=0.1630, acc=94.62% | Val: loss=0.6645, acc=83.44%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:59:38 | INFO | main |   Train: loss=0.1630, acc=94.62% | Val: loss=0.6645, acc=83.44%\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 19:59:38 | INFO | main | Epoch 8/10\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 19:59:38 | INFO | main | Epoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"Training:  14%|â–ˆâ–        | 74/523 [00:43<04:21,  1.71it/s, loss=0.2304, acc=95.78%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nTraining:  15%|â–ˆâ–        | 76/523 [00:45<04:20,  1.72it/s, loss=0.0715, acc=95.85%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 20:05:04 | INFO | main |   Train: loss=0.1253, acc=95.96% | Val: loss=0.9783, acc=77.26%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:05:04 | INFO | main |   Train: loss=0.1253, acc=95.96% | Val: loss=0.9783, acc=77.26%\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:05:04 | INFO | main | Epoch 9/10\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:05:04 | INFO | main | Epoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"Training:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 267/523 [02:36<02:29,  1.72it/s, loss=0.1430, acc=95.93%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nTraining:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 362/523 [03:32<01:33,  1.72it/s, loss=0.0217, acc=96.24%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 20:10:30 | INFO | main |   Train: loss=0.1134, acc=96.23% | Val: loss=0.7971, acc=80.36%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:10:30 | INFO | main |   Train: loss=0.1134, acc=96.23% | Val: loss=0.7971, acc=80.36%\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:10:30 | INFO | main | Epoch 10/10\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:10:30 | INFO | main | Epoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 390/523 [03:47<01:17,  1.72it/s, loss=0.0288, acc=99.01%]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 20:15:56 | INFO | main |   Train: loss=0.0338, acc=99.07% | Val: loss=0.4084, acc=89.11%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:15:56 | INFO | main |   Train: loss=0.0338, acc=99.07% | Val: loss=0.4084, acc=89.11%\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:15:58 | INFO | main |   New best val acc: 89.11% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:15:58 | INFO | main |   New best val acc: 89.11% (checkpoint: best_model.pt)\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:15:59 | INFO | main | Final model saved to /kaggle/working/exp4_InceptionResNetV2-FullBackbone/final_model.pt\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:15:59 | INFO | main | Final model saved to /kaggle/working/exp4_InceptionResNetV2-FullBackbone/final_model.pt\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:15:59 | INFO | main | Training finished. Running final test evaluation...\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:15:59 | INFO | main | Training finished. Running final test evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|â–Œ         | 6/112 [00:02<00:26,  4.06it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 20:16:20 | INFO | main | Test (CE): loss=0.4597, acc=88.69%\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:16:20 | INFO | main | Test (CE): loss=0.4597, acc=88.69%\n","output_type":"stream"},{"name":"stderr","text":"Computing metrics:   5%|â–Œ         | 6/112 [00:02<00:25,  4.10it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n2026-01-29 20:16:40 | INFO | main | Test metrics: accuracy=88.69%, precision=90.01%, recall=89.02%, f1=89.41%, latency=4.98 ms/img, throughput=200.61 img/s\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:16:40 | INFO | main | Test metrics: accuracy=88.69%, precision=90.01%, recall=89.02%, f1=89.41%, latency=4.98 ms/img, throughput=200.61 img/s\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:16:40 | INFO | main | Generating confusion matrix...\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:16:40 | INFO | main | Generating confusion matrix...\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:16:41 | INFO | main | Confusion matrix saved to /kaggle/working/exp4_InceptionResNetV2-FullBackbone/confusion_matrix.png\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:16:41 | INFO | main | Confusion matrix saved to /kaggle/working/exp4_InceptionResNetV2-FullBackbone/confusion_matrix.png\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:16:41 | INFO | main | Training history plot saved to /kaggle/working/exp4_InceptionResNetV2-FullBackbone/training_history.png\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:16:41 | INFO | main | Training history plot saved to /kaggle/working/exp4_InceptionResNetV2-FullBackbone/training_history.png\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:16:41 | INFO | main | Results saved to /kaggle/working/exp4_InceptionResNetV2-FullBackbone/results.json\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:16:41 | INFO | main | Results saved to /kaggle/working/exp4_InceptionResNetV2-FullBackbone/results.json\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:16:41 | INFO | main | \n================================================================================\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:16:41 | INFO | main | \n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:16:41 | INFO | main | âœ… Experiment 4 completed successfully!\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:16:41 | INFO | main | âœ… Experiment 4 completed successfully!\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:16:41 | INFO | main | ðŸ“ All outputs saved to: /kaggle/working/exp4_InceptionResNetV2-FullBackbone\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:16:41 | INFO | main | ðŸ“ All outputs saved to: /kaggle/working/exp4_InceptionResNetV2-FullBackbone\n","output_type":"stream"},{"name":"stderr","text":"2026-01-29 20:16:41 | INFO | main | ================================================================================\n","output_type":"stream"},{"name":"stdout","text":"2026-01-29 20:16:41 | INFO | main | ================================================================================\n\n\n================================================================================\nðŸŽ‰ EXPERIMENT 4 COMPLETED!\n================================================================================\n\nðŸ“Š FINAL RESULTS:\n  Model: inception_resnet_v2\n  Training mode: full\n  Best validation accuracy: 89.11%\n  Test accuracy: 88.69%\n  Test precision: 90.01%\n  Test recall: 89.02%\n  Test F1: 89.41%\n  Inference latency: 4.98 ms/img\n  Throughput: 200.61 img/s\n\nðŸ“ Outputs saved to: /kaggle/working/exp4_InceptionResNetV2-FullBackbone\n  - best_model.pt\n  - final_model.pt\n  - confusion_matrix.png\n  - training_history.png\n  - results.json\n  - training.log\n================================================================================\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## ðŸ“ How to Use This Notebook\n\n### Running Experiments\n\n1. **Change `EXPERIMENT_ID`** in Cell 2 (line 27) to select which experiment to run:\n   - `EXPERIMENT_ID = 1` â†’ Inception v3 (Head only)\n   - `EXPERIMENT_ID = 2` â†’ Inception-ResNet-v2 (Head only)\n   - `EXPERIMENT_ID = 3` â†’ Inception v3 (Full backbone)\n   - `EXPERIMENT_ID = 4` â†’ Inception-ResNet-v2 (Full backbone)\n\n2. **Run all cells** to execute the selected experiment\n\n3. **Outputs will be saved** to `/kaggle/working/exp{N}_{ModelName}/`:\n   - `best_model.pt` - Best model checkpoint\n   - `final_model.pt` - Final model after all epochs\n   - `confusion_matrix.png` - Confusion matrix visualization\n   - `training_history.png` - Training curves\n   - `results.json` - Complete metrics\n   - `training.log` - Detailed logs\n\n### Features\n\nâœ… **Universal code** - One notebook for all 4 experiments  \nâœ… **Auto dataset detection** - Works with different Kaggle dataset structures  \nâœ… **Auto train/val/test split** - Creates splits if not pre-split  \nâœ… **Inception v3** support added  \nâœ… **Model saving** - Both best and final checkpoints  \nâœ… **Confusion matrix** - Visual analysis of predictions  \nâœ… **Detailed logging** - Timestamps, metrics, throughput  \nâœ… **Mixed precision** training for faster execution  \nâœ… **Performance metrics** - Precision, recall, F1, latency, throughput  \n\n### Dataset Structure\n\nThis notebook automatically detects and handles two dataset structures:\n\n1. **Pre-split structure** (preferred):\n   ```\n   dataset/\n   â”œâ”€â”€ train/\n   â”‚   â”œâ”€â”€ class1/\n   â”‚   â”œâ”€â”€ class2/\n   â”‚   ...\n   â”œâ”€â”€ validation/\n   â”‚   â”œâ”€â”€ class1/\n   â”‚   â”œâ”€â”€ class2/\n   â”‚   ...\n   â””â”€â”€ test/\n       â”œâ”€â”€ class1/\n       â”œâ”€â”€ class2/\n       ...\n   ```\n\n2. **Single directory structure**:\n   ```\n   dataset/\n   â”œâ”€â”€ class1/\n   â”œâ”€â”€ class2/\n   ...\n   ```\n   Will automatically split 70/15/15 for train/val/test\n\n### Main Logic Preserved\n\nThe core training logic remains the same as the original:\n- Same data augmentation pipeline\n- Same optimizer and learning rate scheduler\n- Same training loop structure\n- Same evaluation methodology\n\nOnly added: experiment selection, Inception v3, model saving, confusion matrix, enhanced logging, and flexible dataset handling!","metadata":{}},{"cell_type":"code","source":"import shutil\nimport os\n\n# Path to your folder\nfolder_path = \"/kaggle/working/exp4_InceptionResNetV2-FullBackbone\"  # replace with your folder\nzip_path = \"/kaggle/working/exp4_InceptionResNetV2-FullBackbone.zip\"  # output zip file\n\n# Create a zip archive\nshutil.make_archive(base_name=zip_path.replace('.zip',''), format='zip', root_dir=folder_path)\n\nprint(f\"ZIP created at: {zip_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T20:17:35.189923Z","iopub.execute_input":"2026-01-29T20:17:35.190247Z","iopub.status.idle":"2026-01-29T20:18:35.879554Z","shell.execute_reply.started":"2026-01-29T20:17:35.190203Z","shell.execute_reply":"2026-01-29T20:18:35.878918Z"}},"outputs":[{"name":"stdout","text":"ZIP created at: /kaggle/working/exp4_InceptionResNetV2-FullBackbone.zip\n","output_type":"stream"}],"execution_count":24}]}